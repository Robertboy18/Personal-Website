---
title: AI4Science + Mathematics
permalink: /ai4science/
layout: page
excerpt: ai4science
---
<style>
  .centered-image {
    display: block;
    margin-left: auto;
    margin-right: auto;
  }
  .small-image {
    width: 50%;
    height: auto;
  }
</style>

<div style="display: flex;">
  <img src="https://www.robertj1.com/assets/img/operator.jpg" vspace="0"  hspace="0" style="flex: 1;" class="small-image">
  <img src="https://www.robertj1.com/assets/img/lean.jpg" vspace="0"  hspace="0" style="flex: 1;" class="small-image">
</div>

## AI4Math
<p>Our AI4Math initiative blends formal proof with large‐scale learning:</p>
<ul>
  <li><strong>Lean Copilot</strong>: integrating LLMs to autocomplete tactics and suggest proof steps in Lean.</li>
  <li><strong>Lean Agent</strong>: a lifelong learning framework for theorem proving (Kumarappan et al., ICLR 2025).</li>
  <li><strong>Lean Dojo</strong>: interactive dashboards for visualizing proof search and tactic performance.</li>
  <li><strong>Lean Progress</strong>: first of a kind reward model that predicts how much progress you can make on a Lean proof.</li>
</ul>

## AI4Science
<p>Key neural operator projects from our group:</p>
<ul>
  <li><strong>Neural Operator</strong>: learning mappings between function spaces (Kovachki et al., 2021).</li>
  <li><strong>Fourier Neural Operator</strong>: spectral methods for parametric PDEs (Li et al., 2020).</li>
  <li><strong>Physics‑informed NO</strong>: embedding physical constraints into operator learning (Li et al., 2021).</li>
  <li><strong>CoDA‑NO</strong>: Pretraining codomain attention neural operators for multiphysics PDEs (Rahman et al., NeurIPS 2024).</li>
</ul>
